{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dota 2 results prediction\n",
    "\n",
    "Results prediction of Dota 2 games. Data from https://archive.ics.uci.edu/ml/datasets/Dota2+Games+Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about the data from UCI Machine Learning repository page:\n",
    "Attribute Information:\n",
    "Each row of the dataset is a single game with the following features (in the order in the vector):\n",
    "1. Team won the game (1 or -1)\n",
    "2. Cluster ID (related to location)\n",
    "3. Game mode (eg All Pick)\n",
    "4. Game type (eg. Ranked)\n",
    "5 - end: Each element is an indicator for a hero. Value of 1 indicates that a player from team '1' played as that hero and '-1' for the other team. Hero can be selected by only one player each game. This means that each row has five '1' and five '-1' values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92650 entries, 0 to 92649\n",
      "Columns: 117 entries, label to col116\n",
      "dtypes: int64(117)\n",
      "memory usage: 82.7 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10294 entries, 0 to 10293\n",
      "Columns: 117 entries, label to col116\n",
      "dtypes: int64(117)\n",
      "memory usage: 9.2 MB\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "train = pd.read_csv('dota2Train.csv', header = None)\n",
    "test = pd.read_csv('dota2Test.csv', header = None)\n",
    "\n",
    "train = train.add_prefix('col')\n",
    "test = test.add_prefix('col')\n",
    "train = train.rename(columns={'col0': 'label'})\n",
    "test = test.rename(columns={'col0': 'label'})\n",
    "train.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>...</th>\n",
       "      <th>col107</th>\n",
       "      <th>col108</th>\n",
       "      <th>col109</th>\n",
       "      <th>col110</th>\n",
       "      <th>col111</th>\n",
       "      <th>col112</th>\n",
       "      <th>col113</th>\n",
       "      <th>col114</th>\n",
       "      <th>col115</th>\n",
       "      <th>col116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>223</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>136</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  col1  col2  col3  col4  col5  col6  col7  col8  col9  ...  col107  \\\n",
       "0     -1   223     8     2     0    -1     0     0     0     0  ...      -1   \n",
       "1      1   227     8     2     0     0     0     0     0     0  ...      -1   \n",
       "2     -1   136     2     2     1     0     0     0    -1     0  ...       0   \n",
       "3      1   227     2     2    -1     0     0     0     0     0  ...       0   \n",
       "4      1   184     2     3     0     0     0    -1     0     0  ...       0   \n",
       "\n",
       "   col108  col109  col110  col111  col112  col113  col114  col115  col116  \n",
       "0       0       0       0       0       0       0       0       0       0  \n",
       "1       0       0       0       0       0       0       0       0       0  \n",
       "2       0       0       0       0       0       0       0       0       0  \n",
       "3       0       0       0       0       0       0       0       0       0  \n",
       "4       0       0       0       0       0       0       0       0       0  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[223 152 131 154 171 122 224 227 111 151 145 231 188 156 144 153 225 155\n",
      " 186 181 183 121 187 232 185 192 136 123 132 182 161 191 138 137 134 184\n",
      " 112 133 212 204 124 261 213 135 211 241 251]\n",
      "[2 8 6 9 1 3 4 7 5]\n",
      "[2 3 1]\n"
     ]
    }
   ],
   "source": [
    "print(train.col1.unique())\n",
    "print(train.col2.unique())\n",
    "print(train.col3.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns col1, col2 and col3 represents respectively cluster ID, game mode and game type, so they should be transformed to categorical. \n",
    "\n",
    "Columns from col4 to col116 represent different types of heroes and the value indicates if a team chose that hero and which team did it (0 for not chosen, 1 for team 1 and -1 for team -1). If necessary, it can be separated between team 1 and team -1, but I'll leave it like this for now.\n",
    "\n",
    "Next I'll use get_dummies method for encoding col1, col2, col3 and separate the labels from the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = ['col1', 'col2', 'col3']\n",
    "data = pd.concat([train, test])\n",
    "for col in cat_col:\n",
    "    ohe = pd.get_dummies(data[col], prefix=col)\n",
    "    data = pd.concat([data, ohe], axis=1)\n",
    "data.drop(cat_col, axis=1, inplace=True)\n",
    "label_dummie = pd.get_dummies(data['label'], prefix='label')\n",
    "# y will be 1 if the winner is team 1 and 0 if it's -1\n",
    "y_train = label_dummie.iloc[:train.shape[0],1]\n",
    "y_test = label_dummie.iloc[train.shape[0]:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrain = data.iloc[:train.shape[0],:]\n",
    "ttest = data.iloc[train.shape[0]:,:]\n",
    "X_train = ttrain.drop(['label'], axis=1)\n",
    "X_test = ttest.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  col4  col5  col6  col7  col8  col9  col10  col11  col12  ...  \\\n",
      "0     -1     0     0     0     0     0     0      0      0      0  ...   \n",
      "1      1     0     0     0     1     0    -1      0      0      0  ...   \n",
      "2      1     0     0     0     1     0    -1      0      0      0  ...   \n",
      "3      1     0     0     0     0     0     0     -1      0      0  ...   \n",
      "4     -1     0     0     0     0     0    -1      0      0     -1  ...   \n",
      "\n",
      "   col2_3  col2_4  col2_5  col2_6  col2_7  col2_8  col2_9  col3_1  col3_2  \\\n",
      "0       0       0       0       0       0       0       0       0       1   \n",
      "1       0       0       0       0       0       0       0       0       1   \n",
      "2       0       0       0       0       0       0       0       0       1   \n",
      "3       0       0       0       0       0       0       0       0       1   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   col3_3  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       1  \n",
      "\n",
      "[5 rows x 173 columns]\n",
      "   label  col4  col5  col6  col7  col8  col9  col10  col11  col12  ...  \\\n",
      "0     -1     0    -1     0     0     0     0      0      0      1  ...   \n",
      "1      1     0     0     0     0     0     0      0      0      1  ...   \n",
      "2     -1     1     0     0     0    -1     0      0      0      1  ...   \n",
      "3      1    -1     0     0     0     0     0      0      0      1  ...   \n",
      "4      1     0     0     0    -1     0     0      0     -1      0  ...   \n",
      "\n",
      "   col2_3  col2_4  col2_5  col2_6  col2_7  col2_8  col2_9  col3_1  col3_2  \\\n",
      "0       0       0       0       0       0       1       0       0       1   \n",
      "1       0       0       0       0       0       1       0       0       1   \n",
      "2       0       0       0       0       0       0       0       0       1   \n",
      "3       0       0       0       0       0       0       0       0       1   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   col3_3  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       1  \n",
      "\n",
      "[5 rows x 173 columns]\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: label_1, dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "print(ttrain.head())\n",
    "print(ttest.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the categorical data has been encoded, I'll compare a few simple classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier,BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression : 0.5996224215944337  +-  0.003115060178632311\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "lr = LogisticRegression(solver='saga')\n",
    "models.append(lr)\n",
    "#knn = KNeighborsClassifier()\n",
    "#models.append(knn)\n",
    "#dt = DecisionTreeClassifier()\n",
    "#models.append(dt)\n",
    "\n",
    "for m in models:\n",
    "    cv_results = cross_val_score(m, X_train, y_train, cv=8)\n",
    "    result = np.mean(cv_results)\n",
    "    std = np.std(cv_results)\n",
    "    print('%s : %s  +-  %s'%(type(m).__name__,result, std))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 1.0, 'penalty': 'l2'}\n",
      "accuracy : 0.6001295196977874\n"
     ]
    }
   ],
   "source": [
    "lr2 = LogisticRegression(solver = 'lbfgs')\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}\n",
    "lr_cv=GridSearchCV(lr2,grid,cv=10)\n",
    "lr_cv.fit(X_train,y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",lr_cv.best_params_)\n",
    "print(\"accuracy :\",lr_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression's best parameters were C = 1.0 and penalty = l2 for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying some neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64854 samples, validate on 27796 samples\n",
      "Epoch 1/20\n",
      "64854/64854 [==============================] - 42s 642us/sample - loss: 0.6720 - acc: 0.5838 - val_loss: 0.6654 - val_acc: 0.5984\n",
      "Epoch 2/20\n",
      "64854/64854 [==============================] - 39s 604us/sample - loss: 0.6618 - acc: 0.6024 - val_loss: 0.6649 - val_acc: 0.5984\n",
      "Epoch 3/20\n",
      "64854/64854 [==============================] - 41s 628us/sample - loss: 0.6500 - acc: 0.6172 - val_loss: 0.6747 - val_acc: 0.5891\n",
      "Epoch 4/20\n",
      "64854/64854 [==============================] - 39s 598us/sample - loss: 0.6299 - acc: 0.6368 - val_loss: 0.6800 - val_acc: 0.5832\n",
      "Epoch 5/20\n",
      "64854/64854 [==============================] - 41s 629us/sample - loss: 0.5995 - acc: 0.6673 - val_loss: 0.7039 - val_acc: 0.5806\n",
      "Epoch 6/20\n",
      "64854/64854 [==============================] - 41s 636us/sample - loss: 0.5577 - acc: 0.7022 - val_loss: 0.7589 - val_acc: 0.5640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc65423ad50>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "y_train_cat = keras.utils.to_categorical(y_train, 2)\n",
    "n_cols = X_train.shape[1]\n",
    "esm = EarlyStopping(patience=4)\n",
    "\n",
    "mod_nn = Sequential()\n",
    "mod_nn.add(Dense(n_cols, activation='relu', input_shape = (n_cols,)))\n",
    "mod_nn.add(Dense(8*n_cols, activation='relu'))\n",
    "mod_nn.add(Dropout(0.2))\n",
    "mod_nn.add(Dense(2, activation='softmax'))\n",
    "\n",
    "mod_nn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "mod_nn.fit(X_train,y_train_cat, epochs=20, validation_split=0.3, callbacks = [esm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained accuracy as 0.7022, but now we need to test this model against the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10294/10294 [==============================] - 3s 244us/sample - loss: 0.7573 - acc: 0.5618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7573288412424855, 0.56178355]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_cat = keras.utils.to_categorical(y_test, 2)\n",
    "mod_nn.evaluate(X_test,y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network model's accuracy didn't hold up against the test data, probably due to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_nn.save_weights('mod_nn.h5')\n",
    "y_nn_pred = mod_nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should go back and try some feature engineering, parameter tuning and maybe try a few ensemble models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featuring engineering\n",
    "Getting another look at the features, their values and meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['col27', 'col111']\n",
      "0    102944\n",
      "Name: col111, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([train, test])\n",
    "zeroes = []\n",
    "for col in data.columns:\n",
    "    if data[col].value_counts().iloc[0] == 102944:\n",
    "        zeroes.append(col)\n",
    "print(zeroes) #shows if there's any empty hero column\n",
    "print(data.col111.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least 2 columns can be dropped, since they represent heroes that were never chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(zeroes, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all columns are categoricals, I'll use OneHotEncoder on all of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.label\n",
    "y = y.replace(-1,0)\n",
    "y_train_ohe = y[:train.shape[0]]\n",
    "y_test_ohe = y[train.shape[0]:]\n",
    "X = data.drop(['label'], axis=1)\n",
    "onehot = OneHotEncoder(categories='auto')\n",
    "X_ohe = onehot.fit_transform(X)\n",
    "X_ohe.shape\n",
    "X_train_ohe = X_ohe[:train.shape[0],:]\n",
    "X_test_ohe = X_ohe[train.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 38)\t1.0\n",
      "  (0, 48)\t1.0\n",
      "  (0, 57)\t1.0\n",
      "  (0, 60)\t1.0\n",
      "  (0, 63)\t1.0\n",
      "  (0, 66)\t1.0\n",
      "  (0, 69)\t1.0\n",
      "  (0, 72)\t1.0\n",
      "  (0, 75)\t1.0\n",
      "  (0, 78)\t1.0\n",
      "  (0, 81)\t1.0\n",
      "  (0, 84)\t1.0\n",
      "  (0, 88)\t1.0\n",
      "  (0, 90)\t1.0\n",
      "  (0, 93)\t1.0\n",
      "  (0, 96)\t1.0\n",
      "  (0, 100)\t1.0\n",
      "  (0, 102)\t1.0\n",
      "  (0, 105)\t1.0\n",
      "  (0, 108)\t1.0\n",
      "  (0, 110)\t1.0\n",
      "  (0, 114)\t1.0\n",
      "  (0, 117)\t1.0\n",
      "  (0, 120)\t1.0\n",
      "  (0, 122)\t1.0\n",
      "  :\t:\n",
      "  (92649, 318)\t1.0\n",
      "  (92649, 321)\t1.0\n",
      "  (92649, 324)\t1.0\n",
      "  (92649, 327)\t1.0\n",
      "  (92649, 330)\t1.0\n",
      "  (92649, 333)\t1.0\n",
      "  (92649, 336)\t1.0\n",
      "  (92649, 339)\t1.0\n",
      "  (92649, 342)\t1.0\n",
      "  (92649, 345)\t1.0\n",
      "  (92649, 348)\t1.0\n",
      "  (92649, 351)\t1.0\n",
      "  (92649, 354)\t1.0\n",
      "  (92649, 357)\t1.0\n",
      "  (92649, 360)\t1.0\n",
      "  (92649, 363)\t1.0\n",
      "  (92649, 366)\t1.0\n",
      "  (92649, 369)\t1.0\n",
      "  (92649, 372)\t1.0\n",
      "  (92649, 375)\t1.0\n",
      "  (92649, 378)\t1.0\n",
      "  (92649, 381)\t1.0\n",
      "  (92649, 384)\t1.0\n",
      "  (92649, 387)\t1.0\n",
      "  (92649, 390)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train_ohe)\n",
    "#plt.figure(figsize=(5,5))\n",
    "#sns.heatmap(train[['label','col1', 'col2', 'col3']].corr())\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64854 samples, validate on 27796 samples\n",
      "Epoch 1/20\n",
      "64854/64854 [==============================] - 92s 1ms/sample - loss: 0.6801 - acc: 0.5670 - val_loss: 0.6650 - val_acc: 0.5948\n",
      "Epoch 2/20\n",
      "64854/64854 [==============================] - 91s 1ms/sample - loss: 0.6684 - acc: 0.5904 - val_loss: 0.6647 - val_acc: 0.5973\n",
      "Epoch 3/20\n",
      "64854/64854 [==============================] - 93s 1ms/sample - loss: 0.6661 - acc: 0.5934 - val_loss: 0.6640 - val_acc: 0.5988\n",
      "Epoch 4/20\n",
      "64854/64854 [==============================] - 92s 1ms/sample - loss: 0.6650 - acc: 0.5970 - val_loss: 0.6679 - val_acc: 0.5886\n",
      "Epoch 5/20\n",
      "64854/64854 [==============================] - 93s 1ms/sample - loss: 0.6641 - acc: 0.5997 - val_loss: 0.6683 - val_acc: 0.5885\n",
      "Epoch 6/20\n",
      "64854/64854 [==============================] - 99s 2ms/sample - loss: 0.6630 - acc: 0.5993 - val_loss: 0.6652 - val_acc: 0.5968\n",
      "Epoch 7/20\n",
      "64854/64854 [==============================] - 98s 2ms/sample - loss: 0.6618 - acc: 0.6021 - val_loss: 0.6626 - val_acc: 0.5961\n",
      "Epoch 8/20\n",
      "64854/64854 [==============================] - 95s 1ms/sample - loss: 0.6611 - acc: 0.6024 - val_loss: 0.6649 - val_acc: 0.5961\n",
      "Epoch 9/20\n",
      "64854/64854 [==============================] - 96s 1ms/sample - loss: 0.6608 - acc: 0.6033 - val_loss: 0.6641 - val_acc: 0.5960\n",
      "Epoch 10/20\n",
      "64854/64854 [==============================] - 98s 2ms/sample - loss: 0.6594 - acc: 0.6035 - val_loss: 0.6637 - val_acc: 0.5970\n",
      "Epoch 11/20\n",
      "64854/64854 [==============================] - 97s 1ms/sample - loss: 0.6590 - acc: 0.6074 - val_loss: 0.6629 - val_acc: 0.5988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc63e75c4d0>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esm = EarlyStopping(patience=4)\n",
    "n_cols2 = X_train_ohe.shape[1]\n",
    "mod_nn_ohe = Sequential()\n",
    "mod_nn_ohe.add(Dense(n_cols2, activation='relu', input_shape = (n_cols2,)))\n",
    "mod_nn_ohe.add(Dense(8*n_cols2, activation='relu'))\n",
    "mod_nn_ohe.add(Dropout(0.2))\n",
    "mod_nn_ohe.add(Dense(2, activation='softmax'))\n",
    "\n",
    "mod_nn_ohe.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "mod_nn_ohe.fit(X_train_ohe,y_train_cat, epochs=20, validation_split=0.3, callbacks = [esm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10294/10294 [==============================] - 3s 327us/sample - loss: 0.6625 - acc: 0.5886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6625449380898721, 0.5885953]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_nn_ohe.evaluate(X_test_ohe,y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression : 0.5991798220987938  +-  0.0029563386142659113\n",
      "KNeighborsClassifier : 0.520906566465684  +-  0.0034122224690387505\n",
      "DecisionTreeClassifier : 0.5196116425549561  +-  0.004272437180805086\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "lr = LogisticRegression(solver='saga')\n",
    "models.append(lr)\n",
    "knn = KNeighborsClassifier()\n",
    "models.append(knn)\n",
    "dt = DecisionTreeClassifier()\n",
    "models.append(dt)\n",
    "\n",
    "for m in models:\n",
    "    cv_results = cross_val_score(m, X_train_ohe, y_train_ohe, cv=8)\n",
    "    result = np.mean(cv_results)\n",
    "    std = np.std(cv_results)\n",
    "    print('%s : %s  +-  %s'%(type(m).__name__,result, std))   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
