{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dota 2 results prediction\n",
    "\n",
    "Results prediction of Dota 2 games. Data from https://archive.ics.uci.edu/ml/datasets/Dota2+Games+Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about the data from UCI Machine Learning repository page:\n",
    "Attribute Information:\n",
    "Each row of the dataset is a single game with the following features (in the order in the vector):\n",
    "1. Team won the game (1 or -1)\n",
    "2. Cluster ID (related to location)\n",
    "3. Game mode (eg All Pick)\n",
    "4. Game type (eg. Ranked)\n",
    "5 - end: Each element is an indicator for a hero. Value of 1 indicates that a player from team '1' played as that hero and '-1' for the other team. Hero can be selected by only one player each game. This means that each row has five '1' and five '-1' values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92650 entries, 0 to 92649\n",
      "Columns: 117 entries, label to col116\n",
      "dtypes: int64(117)\n",
      "memory usage: 82.7 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10294 entries, 0 to 10293\n",
      "Columns: 117 entries, label to col116\n",
      "dtypes: int64(117)\n",
      "memory usage: 9.2 MB\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "train = pd.read_csv('dota2Train.csv', header = None)\n",
    "test = pd.read_csv('dota2Test.csv', header = None)\n",
    "\n",
    "train = train.add_prefix('col')\n",
    "test = test.add_prefix('col')\n",
    "train = train.rename(columns={'col0': 'label'})\n",
    "test = test.rename(columns={'col0': 'label'})\n",
    "train.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>...</th>\n",
       "      <th>col107</th>\n",
       "      <th>col108</th>\n",
       "      <th>col109</th>\n",
       "      <th>col110</th>\n",
       "      <th>col111</th>\n",
       "      <th>col112</th>\n",
       "      <th>col113</th>\n",
       "      <th>col114</th>\n",
       "      <th>col115</th>\n",
       "      <th>col116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>223</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>136</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  col1  col2  col3  col4  col5  col6  col7  col8  col9  ...  col107  \\\n",
       "0     -1   223     8     2     0    -1     0     0     0     0  ...      -1   \n",
       "1      1   227     8     2     0     0     0     0     0     0  ...      -1   \n",
       "2     -1   136     2     2     1     0     0     0    -1     0  ...       0   \n",
       "3      1   227     2     2    -1     0     0     0     0     0  ...       0   \n",
       "4      1   184     2     3     0     0     0    -1     0     0  ...       0   \n",
       "\n",
       "   col108  col109  col110  col111  col112  col113  col114  col115  col116  \n",
       "0       0       0       0       0       0       0       0       0       0  \n",
       "1       0       0       0       0       0       0       0       0       0  \n",
       "2       0       0       0       0       0       0       0       0       0  \n",
       "3       0       0       0       0       0       0       0       0       0  \n",
       "4       0       0       0       0       0       0       0       0       0  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[223 152 131 154 171 122 224 227 111 151 145 231 188 156 144 153 225 155\n",
      " 186 181 183 121 187 232 185 192 136 123 132 182 161 191 138 137 134 184\n",
      " 112 133 212 204 124 261 213 135 211 241 251]\n",
      "[2 8 6 9 1 3 4 7 5]\n",
      "[2 3 1]\n"
     ]
    }
   ],
   "source": [
    "print(train.col1.unique())\n",
    "print(train.col2.unique())\n",
    "print(train.col3.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns col1, col2 and col3 represents respectively cluster ID, game mode and game type, so they should be transformed to categorical. \n",
    "\n",
    "Columns from col4 to col116 represent different types of heroes and the value indicates if a team chose that hero and which team did it (0 for not chosen, 1 for team 1 and -1 for team -1). If necessary, it can be separated between team 1 and team -1, but I'll leave it like this for now.\n",
    "\n",
    "Next I'll use get_dummies method for encoding col1, col2, col3 and separate the labels from the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = ['col1', 'col2', 'col3']\n",
    "data = pd.concat([train, test])\n",
    "for col in cat_col:\n",
    "    ohe = pd.get_dummies(data[col], prefix=col)\n",
    "    data = pd.concat([data, ohe], axis=1)\n",
    "data.drop(cat_col, axis=1, inplace=True)\n",
    "label_dummie = pd.get_dummies(data['label'], prefix='label')\n",
    "# y will be 1 if the winner is team 1 and 0 if it's -1\n",
    "y_train = label_dummie.iloc[:train.shape[0],1]\n",
    "y_test = label_dummie.iloc[train.shape[0]:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrain = data.iloc[:train.shape[0],:]\n",
    "ttest = data.iloc[train.shape[0]:,:]\n",
    "X_train = ttrain.drop(['label'], axis=1)\n",
    "X_test = ttest.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  col4  col5  col6  col7  col8  col9  col10  col11  col12  ...  \\\n",
      "0     -1     0     0     0     0     0     0      0      0      0  ...   \n",
      "1      1     0     0     0     1     0    -1      0      0      0  ...   \n",
      "2      1     0     0     0     1     0    -1      0      0      0  ...   \n",
      "3      1     0     0     0     0     0     0     -1      0      0  ...   \n",
      "4     -1     0     0     0     0     0    -1      0      0     -1  ...   \n",
      "\n",
      "   col2_3  col2_4  col2_5  col2_6  col2_7  col2_8  col2_9  col3_1  col3_2  \\\n",
      "0       0       0       0       0       0       0       0       0       1   \n",
      "1       0       0       0       0       0       0       0       0       1   \n",
      "2       0       0       0       0       0       0       0       0       1   \n",
      "3       0       0       0       0       0       0       0       0       1   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   col3_3  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       1  \n",
      "\n",
      "[5 rows x 173 columns]\n",
      "   label  col4  col5  col6  col7  col8  col9  col10  col11  col12  ...  \\\n",
      "0     -1     0    -1     0     0     0     0      0      0      1  ...   \n",
      "1      1     0     0     0     0     0     0      0      0      1  ...   \n",
      "2     -1     1     0     0     0    -1     0      0      0      1  ...   \n",
      "3      1    -1     0     0     0     0     0      0      0      1  ...   \n",
      "4      1     0     0     0    -1     0     0      0     -1      0  ...   \n",
      "\n",
      "   col2_3  col2_4  col2_5  col2_6  col2_7  col2_8  col2_9  col3_1  col3_2  \\\n",
      "0       0       0       0       0       0       1       0       0       1   \n",
      "1       0       0       0       0       0       1       0       0       1   \n",
      "2       0       0       0       0       0       0       0       0       1   \n",
      "3       0       0       0       0       0       0       0       0       1   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   col3_3  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       1  \n",
      "\n",
      "[5 rows x 173 columns]\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: label_1, dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "print(ttrain.head())\n",
    "print(ttest.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the categorical data has been encoded, I'll compare a few simple classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier,BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression : 0.5996224215944337  +-  0.003115060178632311\n",
      "KNeighborsClassifier : 0.5294764732103638  +-  0.005517757922634955\n",
      "DecisionTreeClassifier : 0.521813363725558  +-  0.004735803490117447\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "lr = LogisticRegression(solver='saga')\n",
    "models.append(lr)\n",
    "knn = KNeighborsClassifier()\n",
    "models.append(knn)\n",
    "dt = DecisionTreeClassifier()\n",
    "models.append(dt)\n",
    "\n",
    "for m in models:\n",
    "    cv_results = cross_val_score(m, X_train, y_train, cv=8)\n",
    "    result = np.mean(cv_results)\n",
    "    std = np.std(cv_results)\n",
    "    print('%s : %s  +-  %s'%(type(m).__name__,result, std))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 10.0, 'penalty': 'l1'}\n",
      "accuracy : 0.6001187263896385\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "lr2 = LogisticRegression(solver = 'saga')\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}\n",
    "lr_cv=GridSearchCV(lr2,grid,cv=10)\n",
    "lr_cv.fit(X_train,y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",lr_cv.best_params_)\n",
    "print(\"accuracy :\",lr_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression's best parameters were C = 10.0 and penalty = l1 for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying some neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64854 samples, validate on 27796 samples\n",
      "Epoch 1/20\n",
      "64854/64854 [==============================] - 107s 2ms/sample - loss: 0.6737 - acc: 0.5828 - val_loss: 0.6642 - val_acc: 0.5956\n",
      "Epoch 2/20\n",
      "64854/64854 [==============================] - 107s 2ms/sample - loss: 0.6631 - acc: 0.6010 - val_loss: 0.6698 - val_acc: 0.5886\n",
      "Epoch 3/20\n",
      "64854/64854 [==============================] - 119s 2ms/sample - loss: 0.6531 - acc: 0.6145 - val_loss: 0.6747 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "64854/64854 [==============================] - 106s 2ms/sample - loss: 0.6364 - acc: 0.6326 - val_loss: 0.6722 - val_acc: 0.5896\n",
      "Epoch 5/20\n",
      "64854/64854 [==============================] - 101s 2ms/sample - loss: 0.6099 - acc: 0.6553 - val_loss: 0.7021 - val_acc: 0.5793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff9d3e0f890>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "y_train_cat = keras.utils.to_categorical(y_train, 2)\n",
    "n_cols = X_train.shape[1]\n",
    "esm = EarlyStopping(patience=4)\n",
    "\n",
    "mod_nn = Sequential()\n",
    "mod_nn.add(Dense(n_cols, activation='relu', input_shape = (n_cols,)))\n",
    "mod_nn.add(Dense(8*n_cols, activation='relu'))\n",
    "mod_nn.add(Dropout(0.2))\n",
    "mod_nn.add(Dense(8*n_cols, activation='relu'))\n",
    "mod_nn.add(Dropout(0.2))\n",
    "mod_nn.add(Dense(2, activation='softmax'))\n",
    "\n",
    "mod_nn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "mod_nn.fit(X_train,y_train_cat, epochs=20, validation_split=0.3, callbacks = [esm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained accuracy as 0.7022, but now we need to test this model against the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10294/10294 [==============================] - 2s 221us/sample - loss: 0.7002 - acc: 0.5813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7002144329335265, 0.5813095]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_cat = keras.utils.to_categorical(y_test, 2)\n",
    "mod_nn.evaluate(X_test,y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network model's accuracy didn't hold up against the test data, probably due to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_nn.save_weights('mod_nn.h5')\n",
    "y_nn_pred = mod_nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should go back and try some feature engineering, parameter tuning and maybe try a few ensemble models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featuring engineering\n",
    "Giving the features (their values and meaning) a second look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['col27', 'col111']\n",
      "0    102944\n",
      "Name: col111, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([train, test])\n",
    "zeroes = []\n",
    "for col in data.columns:\n",
    "    if data[col].value_counts().iloc[0] == 102944:\n",
    "        zeroes.append(col)\n",
    "print(zeroes) #shows if there's any empty hero column\n",
    "print(data.col111.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least 2 columns can be dropped, since they represent heroes that were never chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(zeroes, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all columns are categoricals, I'll use OneHotEncoder on all of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-245bfa49775c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdota2y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_train_ohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_test_ohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "dota2y = data.label\n",
    "y = y.replace(-1,0)\n",
    "y_train_ohe = y[:train.shape[0]]\n",
    "y_test_ohe = y[train.shape[0]:]\n",
    "X = data.drop(['label'], axis=1)\n",
    "onehot = OneHotEncoder(categories='auto')\n",
    "X_ohe = onehot.fit_transform(X)\n",
    "X_ohe.shape\n",
    "X_train_ohe = X_ohe[:train.shape[0],:]\n",
    "X_test_ohe = X_ohe[train.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_train_ohe)\n",
    "#plt.figure(figsize=(5,5))\n",
    "#sns.heatmap(train[['label','col1', 'col2', 'col3']].corr())\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esm = EarlyStopping(patience=4)\n",
    "n_cols2 = X_train_ohe.shape[1]\n",
    "mod_nn_ohe = Sequential()\n",
    "mod_nn_ohe.add(Dense(n_cols2, activation='relu', input_shape = (n_cols2,)))\n",
    "mod_nn_ohe.add(Dense(8*n_cols2, activation='relu'))\n",
    "mod_nn_ohe.add(Dropout(0.2))\n",
    "mod_nn_ohe.add(Dense(2, activation='softmax'))\n",
    "\n",
    "mod_nn_ohe.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "mod_nn_ohe.fit(X_train_ohe,y_train_cat, epochs=20, validation_split=0.3, callbacks = [esm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_nn_ohe.evaluate(X_test_ohe,y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "lr = LogisticRegression(solver='saga', C=10, penalty='l1')\n",
    "models.append(lr)\n",
    "knn = KNeighborsClassifier()\n",
    "models.append(knn)\n",
    "dt = DecisionTreeClassifier()\n",
    "models.append(dt)\n",
    "\n",
    "for m in models:\n",
    "    cv_results = cross_val_score(m, X_train_ohe, y_train_ohe, cv=8)\n",
    "    result = np.mean(cv_results)\n",
    "    std = np.std(cv_results)\n",
    "    print('%s : %s  +-  %s'%(type(m).__name__,result, std))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes in the features haven't shown any improvement, so we need to keep reviewing the features. The next step is evaluate feature importance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
