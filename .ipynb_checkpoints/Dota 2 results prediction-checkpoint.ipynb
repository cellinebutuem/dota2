{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dota 2 results prediction\n",
    "\n",
    "Results prediction of Dota 2 games. Data from https://archive.ics.uci.edu/ml/datasets/Dota2+Games+Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about the data from UCI Machine Learning repository page:\n",
    "Attribute Information:\n",
    "Each row of the dataset is a single game with the following features (in the order in the vector):\n",
    "1. Team won the game (1 or -1)\n",
    "2. Cluster ID (related to location)\n",
    "3. Game mode (eg All Pick)\n",
    "4. Game type (eg. Ranked)\n",
    "5 - end: Each element is an indicator for a hero. Value of 1 indicates that a player from team '1' played as that hero and '-1' for the other team. Hero can be selected by only one player each game. This means that each row has five '1' and five '-1' values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92650 entries, 0 to 92649\n",
      "Columns: 117 entries, label to col116\n",
      "dtypes: int64(117)\n",
      "memory usage: 82.7 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10294 entries, 0 to 10293\n",
      "Columns: 117 entries, label to col116\n",
      "dtypes: int64(117)\n",
      "memory usage: 9.2 MB\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "train = pd.read_csv('dota2Train.csv', header = None)\n",
    "test = pd.read_csv('dota2Test.csv', header = None)\n",
    "\n",
    "train = train.add_prefix('col')\n",
    "test = test.add_prefix('col')\n",
    "train = train.rename(columns={'col0': 'label'})\n",
    "test = test.rename(columns={'col0': 'label'})\n",
    "train.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>...</th>\n",
       "      <th>col107</th>\n",
       "      <th>col108</th>\n",
       "      <th>col109</th>\n",
       "      <th>col110</th>\n",
       "      <th>col111</th>\n",
       "      <th>col112</th>\n",
       "      <th>col113</th>\n",
       "      <th>col114</th>\n",
       "      <th>col115</th>\n",
       "      <th>col116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>223</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>136</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  col1  col2  col3  col4  col5  col6  col7  col8  col9  ...  col107  \\\n",
       "0     -1   223     8     2     0    -1     0     0     0     0  ...      -1   \n",
       "1      1   227     8     2     0     0     0     0     0     0  ...      -1   \n",
       "2     -1   136     2     2     1     0     0     0    -1     0  ...       0   \n",
       "3      1   227     2     2    -1     0     0     0     0     0  ...       0   \n",
       "4      1   184     2     3     0     0     0    -1     0     0  ...       0   \n",
       "\n",
       "   col108  col109  col110  col111  col112  col113  col114  col115  col116  \n",
       "0       0       0       0       0       0       0       0       0       0  \n",
       "1       0       0       0       0       0       0       0       0       0  \n",
       "2       0       0       0       0       0       0       0       0       0  \n",
       "3       0       0       0       0       0       0       0       0       0  \n",
       "4       0       0       0       0       0       0       0       0       0  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[223 152 131 154 171 122 224 227 111 151 145 231 188 156 144 153 225 155\n",
      " 186 181 183 121 187 232 185 192 136 123 132 182 161 191 138 137 134 184\n",
      " 112 133 212 204 124 261 213 135 211 241 251]\n",
      "[2 8 6 9 1 3 4 7 5]\n",
      "[2 3 1]\n"
     ]
    }
   ],
   "source": [
    "print(train.col1.unique())\n",
    "print(train.col2.unique())\n",
    "print(train.col3.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns col1, col2 and col3 represents respectively cluster ID, game mode and game type, so they should be transformed to categorical. \n",
    "\n",
    "Columns from col4 to col116 represent different types of heroes and the value indicates if a team chose that hero and which team did it (0 for not chosen, 1 for team 1 and -1 for team -1). If necessary, it can be separated between team 1 and team -1, but I'll leave it like this for now.\n",
    "\n",
    "Next I'll use get_dummies method for encoding col1, col2, col3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = ['col1', 'col2', 'col3']\n",
    "data = pd.concat([train, test])\n",
    "for col in cat_col:\n",
    "    ohe = pd.get_dummies(data[col], prefix=col)\n",
    "    data = pd.concat([data, ohe], axis=1)\n",
    "data.drop(cat_col, axis=1, inplace=True)\n",
    "train = data.iloc[:train.shape[0],:]\n",
    "test = data.iloc[train.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  col4  col5  col6  col7  col8  col9  col10  col11  col12  ...  \\\n",
      "0     -1     0     0     0     0     0     0      0      0      0  ...   \n",
      "1      1     0     0     0     1     0    -1      0      0      0  ...   \n",
      "2      1     0     0     0     1     0    -1      0      0      0  ...   \n",
      "3      1     0     0     0     0     0     0     -1      0      0  ...   \n",
      "4     -1     0     0     0     0     0    -1      0      0     -1  ...   \n",
      "\n",
      "   col2_3  col2_4  col2_5  col2_6  col2_7  col2_8  col2_9  col3_1  col3_2  \\\n",
      "0       0       0       0       0       0       0       0       0       1   \n",
      "1       0       0       0       0       0       0       0       0       1   \n",
      "2       0       0       0       0       0       0       0       0       1   \n",
      "3       0       0       0       0       0       0       0       0       1   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   col3_3  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       1  \n",
      "\n",
      "[5 rows x 173 columns]\n",
      "   label  col4  col5  col6  col7  col8  col9  col10  col11  col12  ...  \\\n",
      "0     -1     0    -1     0     0     0     0      0      0      1  ...   \n",
      "1      1     0     0     0     0     0     0      0      0      1  ...   \n",
      "2     -1     1     0     0     0    -1     0      0      0      1  ...   \n",
      "3      1    -1     0     0     0     0     0      0      0      1  ...   \n",
      "4      1     0     0     0    -1     0     0      0     -1      0  ...   \n",
      "\n",
      "   col2_3  col2_4  col2_5  col2_6  col2_7  col2_8  col2_9  col3_1  col3_2  \\\n",
      "0       0       0       0       0       0       1       0       0       1   \n",
      "1       0       0       0       0       0       1       0       0       1   \n",
      "2       0       0       0       0       0       0       0       0       1   \n",
      "3       0       0       0       0       0       0       0       0       1   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   col3_3  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       1  \n",
      "\n",
      "[5 rows x 173 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the categorical data has been encoded, I'll try separate the labels from the data and compare a few simple classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.label\n",
    "y_test = test.label\n",
    "X_train = train.drop(['label'], axis=1)\n",
    "X_test = test.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier,BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression : 0.5996116280532886  +-  0.0031185482418109155\n",
      "KNeighborsClassifier : 0.5294764732103638  +-  0.005517757922634955\n",
      "DecisionTreeClassifier : 0.5246951907592788  +-  0.0033237313741093805\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "lr = LogisticRegression(solver='saga')\n",
    "models.append(lr)\n",
    "#knn = KNeighborsClassifier()\n",
    "#models.append(knn)\n",
    "#dt = DecisionTreeClassifier()\n",
    "#models.append(dt)\n",
    "\n",
    "for m in models:\n",
    "    cv_results = cross_val_score(m, X_train, y_train, cv=8)\n",
    "    result = np.mean(cv_results)\n",
    "    std = np.std(cv_results)\n",
    "    print('%s : %s  +-  %s'%(type(m).__name__,result, std))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/celline/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 1.0, 'penalty': 'l2'}\n",
      "accuracy : 0.6001295196977874\n"
     ]
    }
   ],
   "source": [
    "lr2 = LogisticRegression(solver = 'saga')\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}\n",
    "lr_cv=GridSearchCV(lr2,grid,cv=10)\n",
    "lr_cv.fit(X_train,y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",lr_cv.best_params_)\n",
    "print(\"accuracy :\",lr_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression's best parameters were C = 1.0 and penalty = l2 for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying some neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64854 samples, validate on 27796 samples\n",
      "Epoch 1/3\n",
      "64854/64854 [==============================] - 20s 304us/sample - loss: 0.0012 - acc: 0.9999 - val_loss: 6.3105e-07 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "64854/64854 [==============================] - 19s 298us/sample - loss: 2.8717e-07 - acc: 1.0000 - val_loss: 1.5158e-07 - val_acc: 1.0000\n",
      "Epoch 3/3\n",
      "64854/64854 [==============================] - 19s 292us/sample - loss: 1.3249e-07 - acc: 1.0000 - val_loss: 1.2302e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc6abc67d10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "y_train_cat = keras.utils.to_categorical(y_train, 2)\n",
    "n_cols = X_train.shape[1]\n",
    "esm = EarlyStopping(patience=2)\n",
    "\n",
    "mod_nn = Sequential()\n",
    "mod_nn.add(Dense(173, activation='relu', input_shape = (n_cols,)))\n",
    "mod_nn.add(Dense(346, activation='relu'))\n",
    "mod_nn.add(Dense(2, activation='softmax'))\n",
    "\n",
    "mod_nn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "mod_nn.fit(X_train,y_train_cat, epochs=3, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained accuracy as 1.00, but now we need to test this model against the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10294/10294 [==============================] - 1s 122us/sample - loss: 1.2306e-07 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.23059793774692e-07, 1.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_cat = keras.utils.to_categorical(y_test, 2)\n",
    "mod_nn.evaluate(X_test,y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network model's accuracy holds up against the test data, so now we can save the weights to use it for prediction purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_nn.save_weights('mod_nn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was great and everything, but we should go back to the logistic regression model and try some feature engineering, parameter tuning and maybe try a few ensemble models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(5,5))\n",
    "#sns.heatmap(train[['label','col1', 'col2', 'col3']].corr())\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
